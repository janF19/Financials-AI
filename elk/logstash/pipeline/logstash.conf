input {
  redis {
    host => "logging-redis"
    port => 6379
    data_type => "list"
    key => "backend_logs"
    codec => "json"
    threads => 1 # You can adjust threads per input if needed
    batch_count => 50
  }
  redis {
    host => "logging-redis"
    port => 6379
    data_type => "list"
    key => "worker_logs" # Ensure this matches filebeat-worker.yml
    codec => "json"
    threads => 1
    batch_count => 50
  }
  redis {
    host => "logging-redis"
    port => 6379
    data_type => "list"
    key => "frontend_logs" # Ensure this matches filebeat-frontend.yml
    codec => "json"
    threads => 1
    batch_count => 50
  }
  # Add inputs for nginx_logs and app_redis_logs similarly
}

filter {
  # Keep filter empty for now
  # We will add processing logic back later
}

output {
  stdout {
    codec => rubydebug # This will print logs to Logstash's console
  }
  # UNCOMMENT and enable Elasticsearch output
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "%{[@metadata][target_index_prefix]}-logs-%{+YYYY.MM.dd}" # If using the filter above
    # Or, if you want to test one service at a time with a simple index:
    # index => "app-%{[log_source_service]}-logs-%{+YYYY.MM.dd}" # (Requires log_source_service field from Filebeat)
  }
}